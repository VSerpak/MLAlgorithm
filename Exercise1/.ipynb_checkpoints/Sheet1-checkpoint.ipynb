{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning in Life Scicence WS 2016 - 2017\n",
    "## Exercise 1 - Dataset  \n",
    "a) Create a dataset in R^2 with two classes (positive with target 1 and negative with target 0). Consider 100 datapoints for each class. Let the instances for each class be sampled from a bivariate Gaussian distribution with the same variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function min in module builtins:\n",
      "\n",
      "min(...)\n",
      "    min(iterable, *[, default=obj, key=func]) -> value\n",
      "    min(arg1, arg2, *args, *[, key=func]) -> value\n",
      "    \n",
      "    With a single iterable argument, return its smallest item. The\n",
      "    default keyword-only argument specifies an object to return if\n",
      "    the provided iterable is empty.\n",
      "    With two or more arguments, return the smallest argument.\n",
      "\n",
      "[3, 4, 5, 6, 8, 10, 9, 12, 15]\n",
      "[2, 3]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# Implementation taken from the sklearn website:\n",
    "# https://docs.scipy.org/doc/numpy/reference/generated/numpy.random.multivariate_normal.html\n",
    "help (min)\n",
    "\n",
    "lst1 = [1, 2, 3]\n",
    "lst2 = [3, 4, 5]\n",
    "print ( [x * y for x in lst1 for y in lst2])\n",
    "\n",
    "print ([x for x in lst1 if 4 > x > 1])\n",
    "print ( [1] * 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Importing numpy and matplotlib\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Settings\n",
    "## Creating dataset here, 100 data points \n",
    "# numpy.random.multivariate_normal(mean, cov[size])\n",
    "# Draw random samples from multivariate normal distribution\n",
    "mean = [0, 0]\n",
    "cov = [[0.7,0.5 ], [0.5, 0.5]] # diagonal variance \n",
    "n = 1000 # number of points \n",
    "#Diagonal covariance means that points are oriented along x or y-axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Example taking from the website of sklearn\n",
    "# Here we are considering \"X\" is for multivariate\n",
    "\n",
    "x = np.random.multivariate_normal(mean, cov, n )\n",
    "y = []\n",
    "\n",
    "for (x1,x2) in x:\n",
    "    if x1 >= 0:\n",
    "        y.append(1)\n",
    "    else:\n",
    "        y.append(0)\n",
    "\n",
    "#plt.scatter(x[:,0],x[:,1]  , c = 'yellow')\n",
    "#plt.axis('equal')\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Apply Linear Model on different type of distributions\n",
    "# Split the data into training/testing sets\n",
    "trainX =x[:-20] # take 80 sample dataset as a Training\n",
    "testX = x[-20:] # take 20 sample datset for testing\n",
    "\n",
    "\n",
    "# Split target also into training/ testing sets\n",
    "trainY =  [0] * len(XNegative[:-20]) + [1] * len(XPositive[:-20])\n",
    "testY =   [0] * len(XNegative[-20:]) + [1] * len(XPositive[-20:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Example taking from the website of sklearn\n",
    "# Here we are considering \"X\" is univariate\n",
    "x = np.random.multivariate_normal(mean, cov, n )\n",
    "XPositive = [val for val in x[:,1]  if val >= 0]\n",
    "XNegative = [val for val in x[:,1]  if val < 0]\n",
    "#plt.scatter(x[:,0],x[:,1]  , c = 'yellow')\n",
    "#plt.axis('equal')\n",
    "#plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "YPositive = [1] * len(XPositive)\n",
    "YZero = [0] * len(XNegative)\n",
    "#plt.scatter(XPositive, YPositive, color='black')\n",
    "#plt.scatter(XNegative, YZero , color='red')\n",
    "#plt.axis('equal')\n",
    "#plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2 - Linear Model\n",
    "a) Write the code to compute a Linear classification model. Apply it to the dataset created in Exercise 1. Plot the predicted class for a regular grid in R^2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Apply Linear Model on different type of distributions\n",
    "# Split the data into training/testing sets\n",
    "trainX =XNegative[:-20]  +  XPositive[:-20]# take 80 sample dataset as a Training\n",
    "testX = XNegative[-20:] +  XPositive[-20:] # take 20 sample datset for testing\n",
    "\n",
    "\n",
    "# Split target also into training/ testing sets\n",
    "trainY =  [0] * len(XNegative[:-20]) + [1] * len(XPositive[:-20])\n",
    "testY =   [0] * len(XNegative[-20:]) + [1] * len(XPositive[-20:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#Converting List to  array for parsing\n",
    "trainX = np.asarray(trainX)\n",
    "trainY= np.asarray(trainY)\n",
    "\n",
    "trainX= trainX.reshape(trainX.size, 1)\n",
    "trainY= trainY.reshape(trainY.size, 1)\n",
    "\n",
    "testX = np.asarray(testX)\n",
    "testX = testX.reshape(testX.size, 1)\n",
    "\n",
    "testY =  np.asarray(testY)\n",
    "testY = testY.reshape(testY.size,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Model Starts Here:\n",
      "Coefficients: [[ 0.57804165]]\n",
      "[[-0.07482969]]\n",
      "Mean squared error: 0.00\n",
      "Variance score: 0.59\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgwAAAFkCAYAAABMyWOlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAPYQAAD2EBqD+naQAAIABJREFUeJzt3XucXWV97/HPz+GeYoKJJkAhCEkQrAiJCCgBEoRRFPBa\nHLUgHhUOQmnqtfX0tNqjVOQmKtUKAtU6ysvWcik3uchFIeAMYIGQhCRcJCFoQoMawiXznD/WBCeT\n7L3WTvba18/79dovmbWftfZvrRVnf+d5nrVWpJSQJEmq5mXNLkCSJLU+A4MkScplYJAkSbkMDJIk\nKZeBQZIk5TIwSJKkXAYGSZKUy8AgSZJyGRgkSVIuA4MkScpVamCIiL+JiLsi4pmIWB4RP4mIaQXW\nOywiBiJiTUQsiIgTyqxTkiRVV3YPw0zg68ABwFuALYHrI2LbSitExG7AVcCNwOuBrwEXRsQRJdcq\nSZIqiEY+fCoiJgBPAYeklG6v0OYrwNtSSvuMWNYPjE0pHdWYSiVJ0kiNnsMwDkjAyiptDgRuGLXs\nOuCgsoqSJEnVbdGoD4qIAM4Dbk8pPVil6SRg+ahly4GXR8TWKaXnRm13PNALPAKsqV/FkiR1vG2A\n3YDrUkorqjVsWGAALgD2Bt5c5+32Av9W521KktRNPgj8oFqDhgSGiPgGcBQwM6W0LKf5k8DEUcsm\nAs+M7l0Y9gjA97//ffbaa6/NLbWqOXPmcO6555b6Gdo0npvW5vlpXZ6b1tWIczNv3jw+9KEPwfB3\naTWlB4bhsHAscGhK6bECq9wBvG3UsiOHl2/MGoC99tqL6dOnb3KdRYwdO7b0z9Cm8dy0Ns9P6/Lc\ntK4Gn5vcIf2y78NwAVk3xweAP0TExOHXNiPafDkiLh2x2reA3SPiKxGxZ0ScArwXOKfMWiVJUmVl\nXyVxMvBy4GfA0hGvPx/RZkdgl3U/pJQeAd5Odt+Ge4E5wP9KKY2+ckKSJDVIqUMSKaXcQJJSOnEj\ny24FZpRSlCRJqpnPkqhBX19fs0tQBZ6b1ub5aV2em9bVauemoXd6LENETAcGBgYGnLgjSVINBgcH\nmTFjBsCMlNJgtbb2MEiSpFwGBkmSlMvAIEmSchkYJElSLgODJEnKZWCQJEm5DAySJCmXgUGSJOUy\nMEiSpFwGBkmSlMvAIEmSchkYJElSLgODJEnKZWCQJEm5DAySJCmXgUGSJOUyMEiSpFwGBkmSlMvA\nIEmSchkYJElSLgODJEnKZWCQJEm5DAySJCmXgUGSJOUyMEiSpFwGBkmSlMvAIEmSchkYJElSLgOD\nJEnKZWCQJEm5DAySJCmXgUGSJOUyMEiSpFwGBkmSSnLDDTBlChx4IHzzm82uZvNs0ewCJEnqNMuW\nwU47/fHnRYtg7lzYZx+YObN5dW0OexgkSaqTtWth9uz1w8JIS5c2tp56MjBIklQH550HW2wBN9+8\n8fe33hp6extbUz05JCFJ0ma46y444ID8dvPnw7hx5ddTFnsYJEnaBE8/Ddttlx8WLr8cUoLJkxtT\nV1lKDQwRMTMiroiIJyJiKCKOyWl/6HC7ka+1EfGqMuuUJKmolOADH4BXvAKefbZyu1NPzdoeU/Wb\nr32UPSQxBrgXuAj4j4LrJGAa8LuXFqT0VP1LkySpNt//PvzFX1Rvs8suMG8ejBnTmJoapdTAkFK6\nFrgWICKihlV/k1J6ppyqJEmqzUMPwV575be7/3547WvLr6cZWnEOQwD3RsTSiLg+It7U7IIkSd1p\n9WrYfff8sPDd72bDD50aFqD1AsMy4CTgPcC7gceBn0XEvk2tSpLUdf76r7NhhSVLKrd53/tgaAhO\nPLFxdTVLS11WmVJaACwYsejOiNgDmAOcUG3dOXPmMHbs2PWW9fX10dfXV/c6JUmd67/+C97xjupt\nttwSnnwym/jYLvr7++nv719v2apVqwqvHymlete08Q+KGALemVK6osb1zgTenFJ6c4X3pwMDAwMD\nTJ8+vQ6VSpK60eOPw6675rf7xS/goIPKr6cRBgcHmTFjBsCMlNJgtbatNiSxMfuSDVVIklR3L7wA\nb3pTflg488xsnkKnhIValTokERFjgClkExkBdo+I1wMrU0qPR8QZwE4ppROG258OLAEeALYBPgbM\nAo4os05JUnf6p3+Cv/mb6m1mzoSbbspu+9zNyt79NwA3k91bIQFnDy+/FPgIMAnYZUT7rYbb7ASs\nBn4FHJ5SurXkOiVJXeTnP4eDD85v9+tfw847l19POyj7Pgy3UGXYI6V04qifvwp8tcyaJEnda8UK\neOUrs6GFaq65Bt761sbU1C7aYQ6DJEmbZWgI3v1umDChelj41Key9w0LG+ryERlJUqe76CL46Eer\nt5k6Fe67D7bdtjE1tSMDgySpI/33f8M+++S3e+gh2HPP8utpdw5JSJI6yu9/DzvumB8WfvCDbPjB\nsFCMgUGS1BFSgpNPhu23z+7CWMkJJ2RzGrwRcG0ckpAktb2f/CSb1FjN2LHw6KPZ/6p2BgZJUtta\nsiR7mmSeX/4Ssjsga1M5JCFJajvPPw/77ZcfFs4/PxuqMCxsPgODJKmt/MM/wNZbw733Vm5zxBHw\n4otw2mkNK6vjOSQhSWoLN98Ms2fnt1u2DCZNKr+ebmNgkCS1tOXLiwWAG28sFii0aRySkCS1pLVr\ns1s054WFv/u7bJ6CYaFc9jBIklrON78Jp55avc3rXw9z52bzGVQ+A4MkqWUMDha7omHRomKXU6p+\nHJKQJDXdqlUwblx+WPjxj7PhB8NC4xkYJElNkxJ8+MNZWFi1qnK7k07Kbuf8nvc0rDSN4pCEJKkp\nfvjD/Oc5TJwICxdmz4dQcxkYJEkNtXAhTJuW3+6++4o9nlqN4ZCEJKkh1qyB17wmPyx8+9vZUIVh\nobUYGCRJpfvc52DbbWH+/Mptjj02u/fCxz/euLpUnEMSkqTSXHdddvOlPL/5DUyYUH492nQGBklS\n3S1dCjvvnN/u1lth5szy69Hmc0hCklQ3L74Ihx2WHxa+9KVsnoJhoX3YwyBJqouzz4ZPfap6mwMO\ngNtugy23bExNqh8DgyRps8ydCwcemN/u0Udh113Lr0flcEhCkrRJVq7MHvyUFxauuCIbfjAstDcD\ngySpJinBccfB+PHw/POV2/3lX2Ztjz66cbWpPA5JSJIKu/TS7NkP1UyeDA8+CNtt15CS1CAGBklS\nrgcfhNe+Nr/dAw/A3nuXX48azyEJSVJFq1dnPQZ5YeHSS7PhB8NC5zIwSJI26vTTYcwYeOyxym3e\n//7ssdPHH9+4utQcDklIktZz5ZVwzDHV22y9NSxbBjvs0Jia1HwGBkkSkPUkTJ6c3+7OO7MbMKm7\nOCQhSV3uuedg++3zw8JZZ2XzFAwL3ckeBknqYtttB88+W73NrFlw/fWwhd8YXc0eBknqQl/+MkTk\nh4UnnoCbbjIsyB4GSeoq8+YVu/TxuuvgyCPLr0ftw8AgSV1g7dpivQTHHQc//GH59aj9GBgkqcO9\n4Q0wMJDf7umnYdy48utRe3IOgyR1qO99L5unkBcWrr46u/rBsKBqSg0METEzIq6IiCciYigicm4F\nAhFxWEQMRMSaiFgQESeUWaMkdZply7KgkHf3xXe+MwsKb3tbY+pSeyt7SGIMcC9wEfAfeY0jYjfg\nKuAC4APAW4ALI2JpSumn5ZUpSe0vJXhZwT8Dh4ayUCEVVWpgSCldC1wLEFHon+b/BhanlD4z/PP8\niDgYmAMYGKQOcN111zF37lwOOuggjjjiiI22WbBgAYsWLWLKlCmklF7676lTp6733tSpUze6zsjl\n1badt/6CBQu45ZZbiAgOPfTQmj9v5L5Onjy5YvtK+1vpvzf2eX19xSYrPvYY7LJL8eOizdcxxzal\n1JAXMAQck9PmFuCcUcs+DDxdZZ3pQBoYGEiSWtfDDz+cxo8fn4CXXuPHj0+LFy9+qc2KFStSb2/v\nem1Gtx/5c29vb1q0aNEG6/T29qaVK1eu9/kb23al9WfNmpVmzpy5wefPnj270OdtbF831j5vf/PW\nTyml669PKetbqP76znc2fl4qHZfRx0+1a4djOzAwsK626SnvezyvQb1eBQPDfOCzo5a9DVgLbF1h\nHQOD1AYqfYGOHz/+pTa9vb2pp6en8BdnT09PGj9+/Abr9PT0pN7e3vU+f2PbrrR+tVeRz6sWFka2\nr3V/R65/+OHvLBQU9t67+nmpdFxGHz/Vrh2OrYFBUku59tprq34BXn/99Wn+/Pk1f3HmvRYsWJBS\nSqVsu9Ln5e1rfV7FehWef776eck7LuuOn2rXLse2lsDQavdheBKYOGrZROCZlNJz1VacM2cOY8eO\nXW9ZX18ffX199a1QUs3mzp1b9f077riDF198se6f+/DDDzN16lQWLVpU921X+ry77767xE/4f8Dn\nc1v96lfwutflby3vuKw7fqpdKx7b/v5++vv711u2atWqwuu3WmC4g6xHYaQjh5dXde655zJ9+vRS\nipK0eQ7IebzhukmB9TZlyhQA9thjj7pvu9LnvazoZQo12R+4K7fV//2/8IUvFN9q3nFZd/xUu1Y8\nthv7I3pwcJAZM2YUWr/s+zCMiYjXR8S+w4t2H/55l+H3z4iIS0es8q3hNl+JiD0j4hTgvcA5ZdYp\nqVy9vb2MHz9+o++NHz+eI444gmnTptHb20tPT0/h7fb09DB+/PgN1unp6aG3t/elv+AqbbvS+tXk\nfV61fR3dPn9/tybrLc4PCynVFhag+nEZefxUu448tnljFpvzAg4lm7uwdtTru8PvXwzcNGqdQ4AB\n4FlgIfAXOZ/hHAapDSxevDj3KomVK1fWfJXE4sWLC81E39i2K60/e/bsdMghh2zw+bNnzy70eRvb\n1421r76/xeYp/O53m3deKh2XVprJ367a4djWMochUval27YiYjowMDAw4JCE1AZ++tOfcscdd1S9\nD8PChQt5+OGHX+q2XfffU6dOXe+9kX+lVVpebdt56y9cuJBbbrkFYIP7MBT5vJH7uttuu1VsP3Jb\n73rXLjzwwDbVDiGQPXJ61qzcZoUVPX6qXSsf2xFDEjNSSoPV2hoYJKkF3H47zJyZ3+4974Ef/7j8\netQdagkMrTbpUZK6ytAQFJ1C4e2c1Uw+rVKSmiSiWFi4775sxoJhQc1kYJCkBjv55GJf/scckwWF\nffYpvyYpj0MSktQgS5bA7rsXa9vm08vUgQwMktQARYcTnn8ettyy3FqkTeGQhCSVaNq0YmHhyiuz\nXgXDglqVgUGSSnDppVlQWLiwertXvjILCu94R2PqkjaVQxKSVEfPPAOjnoNXkfMU1E7sYZCkOoko\nFhZWrjQsqP0YGCRpMx18cLF5CpddlgWFHXYovyap3hySkKRNdOutcOihxdrao6B2Z2CQpBqtXQtb\nFPztaVBQp3BIQpJqEFEsLCxZYlhQZzEwSFIBhx5abJ7Cpz+dBYXddiu9JKmhHJKQpCruvRf2269Y\nW3sU1MkMDJJUQdHbOa9dCy+zv1Ydzn/ikjRKRLGwcM01Wa+CYUHdwH/mkjTs058uFhR22CELCm99\na/k1Sa3CIQlJXW/pUth552JtnaegbmVgkNTVis5TeOYZ2H77cmuRWplDEpK6UtF5Cuedl/UqGBbU\n7QwMkrrK2WcX71VICU4/vdx6pHbhkISkrrBmDWy7bbG2zlOQNmQPg6SOF1EsLDz0kGFBqsTAIKlj\n7b13seGHmTOzoLDnnuXXJLUrhyQkdZyf/xwOPrhYW3sUpGIMDJI6Ri13XRwaKj75UZJDEpI6RESx\nsHDbbVmwMCxItTEwSGprX/pSsS//PffMgkLRoQpJ63NIQlJbevJJ2HHHYm2dpyBtPgODpLZTdDjh\n2Wdhm23KrUXqFg5JSGobEyYUCwsXX5z1KhgWpPqxh0FSy7vsMjjuuPx2O+6YPXlSUv0ZGCS1rNWr\nYcyYYm2dpyCVyyEJSS0polhY+O1vDQtSIxgYJLWUk08uNk/ha1/LgsL48eXXJMkhCUkt4qGHYK+9\nirW1R0FqPAODpKYaGoKenmJtDQpS8zgkIalpdtqpWFiYP9+wIDWbgUFSw110UTZPYdmy6u1OOikL\nCtOmNaYuSZWVPiQREZ8APgVMAu4DTksp3V2h7aHAzaMWJ2DHlNJTpRYqqXSrVsG4cfnt/uRP4He/\nK78eScWV2sMQEccBZwN/D+xHFhiui4gJVVZLwFSygDEJw4LUEa6+ulhYePFFw4LUisoekpgDfDul\n9K8ppYeAk4HVwEdy1vtNSumpda+Sa5RUooUL4eij4e1vr97uvvuy4YeiEyAlNVZpgSEitgRmADeu\nW5ZSSsANwEHVVgXujYilEXF9RLyprBollWfVKvj0p+G1r4Wrrqrc7q/+KgsK++zTuNok1a7MOQwT\ngB5g+ajly4E9K6yzDDgJ+CWwNfAx4GcR8caU0r1lFSqpfoaGsoc//e3fwlM5/YNe+SC1j5a6D0NK\naQGwYMSiOyNiD7KhjROqrTtnzhzGjh273rK+vj76+vrqXqekjbv99qzHYGBg4+9PnAhnnAEnnAAv\n8xotqaH6+/vp7+9fb9mqVasKrx+ppIg/PCSxGnhPSumKEcsvAcamlN5VcDtnAm9OKb25wvvTgYGB\ngQGmT5+++YVLqtkPfwjVsvmWW8KcOfD5z8PLX964uiRVNzg4yIwZMwBmpJQGq7UtrYchpfRCRAwA\nhwNXAEREDP98fg2b2pdsqEJSi3n8cdh11+ptjj4azj4bpk5tTE2SylH2kMQ5wCXDweEusqGF7YBL\nACLiDGCnlNIJwz+fDiwBHgC2IZvDMAs4ouQ6JdVg7VrYIue3x157wXnnwZFHNqYmSeUqNTCklC4b\nvufCF4GJwL1Ab0rpN8NNJgG7jFhlK7L7NuxENpzxK+DwlNKtZdYpqbgiT5I8+WQ4//xsKEJSZyh9\n0mNK6QLgggrvnTjq568CXy27Jkm1+9jH4MIL89v9/OfwJi+GljqO85QlVTVvXtarkBcWPve57DJJ\nw4LUmVrqskpJrSOl4pc+Dg0VG6qQ1L7sYZC0gYhiYeGuu7JgYViQOp+BQdJLTj+92Jf/UUdlQWH/\n/cuvSVJrcEhCEkuXws47F2vr7Zyl7mRgkLpc0eGE1ath223LrUVS63JIQupSEcXCwne/m/UqGBak\n7mZgkLrMhRcW71VICU48Mb+dpM7nkITUJVavhjFjirV1noKk0exhkLpARLGw8OijhgVJG2dgkDrY\n5MnFhh8+9rEsKOQ9eVJS93JIQupAV14JxxxTrK09CpKKMDBIHWRoCHp6irf1Do2SinJIQuoQEcXC\nwi9+4e2cJdXOwCC1uQMOKPbl/2d/lgWFgw4qvyZJncchCalNLVgAe+5ZrK3zFCRtLgOD1Ia8nbOk\nRnNIQmojRW/nfO653s5ZUn3ZwyC1gY9/HL7znWJtHX6QVAYDg9TCVqyACROKtTUoSCqTQxJSi4oo\nFhaWLjUsSCqfgUFqMUXnKbz97VlQ2HHH8muSJAOD1CLOOqu2x05fdVW59UjSSM5hkJrshRdgq62K\ntXXoQVKz2MMgNVFEsbBw222GBUnNZQ+D1ARFhx623BKef77cWiSpCHsYpAa68cba5ikYFiS1CnsY\npAYpGhSefz7rWZCkVmIPg1SyopdJnnFG1qtgWJDUiuxhkEoyYwYMDhZr64RGSa3OwCDV2SOPwKtf\nXaytQUFSuzAwSHVUdJ7CsmUwaVK5tUhSPTmHQaqDovMU3vrWrFfBsCCp3RgYpM3wmc/UdpnkNdeU\nW48klcUhCWkTrF4NY8YUa+s8BUmdwB4GqUYRxcLCHXcYFiR1DnsYpIKKDj2AQUFS57GHQcrx4x/X\nNk/BsCCpE9nDIFWQErysYKReu7Z4W0lqR/6KkzYiolgA+Jd/qS1YSFK7sodBGmHSJFi+vFhbhx4k\ndZPS/y6KiE9ExJKIeDYi7oyI/XPaHxYRAxGxJiIWRMQJZdco3X9/1qtQJCw4T0FSNyq1hyEijgPO\nBj4O3AXMAa6LiGkppd9upP1uwFXABcAHgLcAF0bE0pTST2suYMECWLQIpkyBqVM3eT+aop61d8px\nSKnYfixYALfckiWAQw/dsO2o41F0QuP//A+MHbvpu1JI3rmqtG8jl++6azapopZjVmst697r6fnj\nZ02d2t7/1iRVl1Iq7QXcCXxtxM8B/Br4TIX2XwF+NWpZP3B1lc+YDqSBgYH0khUrUurtXfeHYPbq\n7U1p5crU8upZe6cdh7z9WLEipVmzNmw7e3bWdtQ2K2169OsjH2nS/o7cx0r7NnNmSgcfXGxHip77\narVUOy/jx7fnvzWpiw0MDCQgAdNT3nd6XoNNfQFbAi8Ax4xafgnwkwrr3AKcM2rZh4Gnq3zOhoGh\ntzelnp71f3n19GTLW109a++045C3H5W+yCKy94a3eTyXFA4LTd3fkftYLTwVfRU999VqyTsv7fhv\nTepirRIYdgSGgANGLf8KcEeFdeYDnx217G3AWmDrCuusHxjmz6/+S2zBgnof7/qpZ+2dfBw2th8F\n1nmascWDQiOPU17t1123aQFhU859Lce+Hp8nqalqCQwdc5XEnDlzGDt2LDz11EvL+oZf63n44dYd\nW120qPr7tdRez201Wl7tI63bj5x1glRocw+wN3szb8Ptlylvf++8s76fV22fajn29fg8SQ3T399P\nf3//estWrVpVeP0yA8NvyXoGJo5aPhF4ssI6T1Zo/0xK6blqH3buuecyffr0bNLVnntWbjhlSrXN\nNNcee1R/v5ba67mtRsurfaR1+1FhnaJBYSee4An+tPL2y5S3vwceWN/Pq7ZPtRz7enyepIbp6+uj\nr2/9P6MHBweZMWNGofVLu6wypfQCMAAcvm5ZRMTwz7+osNodI9sPO3J4eTHTpkFvbzZ7e6Senmx5\nK/+lU8/aO/E4jDR6P9atM+zbfLxwWEjjJ/BEz+Tq2y9T3rk68sj19m2TFdmnvFryzkutnyepfeSN\nWWzOC/hzYDVwPPAa4NvACuCVw++fAVw6ov1uwO/I5jnsCZwCPA+8pcpnbDjpceXK9r06oJ61d9px\nyNuPlSvT2lmHFx5aH1q3ncWLm3+c8s7VypXZ1R6jd+KQQ7IrJYrscNF9qlZLtfPiVRJS26llDkOk\nVOyvsE0VEacAnyEbWrgXOC2l9Mvh9y4GJqeUZo9ofwhwLrA32SWYX0wpfa/K9qcDAwMDA9mQxEgL\nF2bjp+14TXg9a++U4wBV96Po/RT+/etLefce9224nVY4Tnk1LFyY3W8B1r8Pw8jlkyfDiy8WOmab\nXMu697bY4o+fNXVqaxxDSYWNGJKYkVIarNa29MBQtqqBQV3hLW+BG28s1rbN/7lLUl3VEhg65ioJ\ndZ9582DvvYu1NShI0uYxMKgtFR1+WL0att223FokqRv4UF61lYhiYeHii7NeBcOCJNWHgUFt4fOf\nL96rkBJ8+MOlliNJXcchCbW0Z54p/oRI5ylIUnnsYVDLiigWFpYvNyxIUtkMDGo5739/seGH00/P\ngsKrXlV+TZLU7RySUMu4+2544xuLtbVHQZIay8Cgplu7NrthYBEGBUlqDock1FQRxcLC/PmGBUlq\nJgODmuILXyg2T+HLX86CwrRp5dckSarMIQk11KOPwm67FWtrj4IktQ4Dgxqm6I2X1q6Fl9n3JUkt\nxV/LKt2kScXCwuBg1qtgWJCk1uOvZpXm+9/PgsLy5dXbHX98FhT2268xdUmSaueQhOpu1SoYN65Y\nW+cpSFJ7MDCornzstCR1JockVBe9vcXCwpVX+thpSWpH9jBos9xyCxx2WH67ffeFe+4pvRxJUkkM\nDNokL7wAW21VrK3zFCSp/TkkoZpFFAsLPnZakjqHgUGFffKTxeYpfOMbPnZakjqNQxLKtWAB7Lln\nsbb2KEhSZzIwqKJa7ro4NFT8kkpJUvtxSEIbtcUWxcLCgw9mwcKwIEmdzcCg9fzzP2df/mvXVm93\n2mlZUNhrr8bUJUlqLockBMBvflN8kqLzFCSp+xgYVHg44bnnit97QZLUWRyS6GJvfGOxsHDTTVmv\ngmFBkrqXgaELXXttFhTuvrt6u9mzs6Awa1Zj6pIktS6HJLrImjXFH/rkPAVJ0kj2MHSJiGJhYeVK\nw4IkaUMGhg53/vnF5ilcckkWFHbYofSSJEltyCGJDvXoo7Dbbvntxo2Dp58uvRxJUpszMHQYb+cs\nSSqDQxId5KijioWFxYu9nbMkqTYGhg5wxRXZl/8111Rv97WvZUHh1a9uTF2SpM7hkEQbW7kSxo/P\nb3fwwXDbbeXXI0nqXAaGNlV0OOHFF6Gnp9xaJEmdzyGJNnPaacXCwoIF2fCDYUGSVA+lBYaI2CEi\n/i0iVkXE0xFxYUSMyVnn4ogYGvW6uqwa28mdd2ZB4RvfqN7urLOyoDB1amPqkiR1hzKHJH4ATAQO\nB7YCLgG+DXwoZ71rgA8D6/6Ofq6c8tpD0ds5T5iQPaJakqQylBIYIuI1QC8wI6V0z/Cy04D/iohP\npZSerLL6cyklv/rIQsCKFfntnn0Wttmm/HokSd2rrCGJg4Cn14WFYTcACTggZ93DImJ5RDwUERdE\nxCtKqrFlnXtuNvyQFxbuvDMbfjAsSJLKVtaQxCTgqZELUkprI2Ll8HuVXAP8O7AE2AM4A7g6Ig5K\nqfMfibRiRdarkOe007JnREiS1Cg1BYaIOAP4bJUmCdhrU4tJKV024scHIuK/gUXAYcDNm7rdVjc0\nBO99L/zkJ/ltOz82SZJaUa09DGcBF+e0WQw8Cbxq5MKI6AFeMfxeISmlJRHxW2AKOYFhzpw5jB07\ndr1lfX199PX1Ff24prjoIvjoR/PbrVgBr+i6wRlJUr309/fT39+/3rJVq1YVXj/K6OkfnvT4APCG\nEZMejwSuBv40Z9LjyO38KfAocGxK6aoKbaYDAwMDA0yfPr0u9TfC/ffD616X3+7yy+GYY8qvR5LU\nfQYHB5kxYwZkFykMVmtbyqTHlNJDwHXAdyJi/4h4M/B1oH9kWBie2Hjs8H+PiYgzI+KAiJgcEYcD\n/wksGN6lzbdfAAAH1klEQVRWR/j972GnnfLDwve+lw0/GBYkSa2gzDs9fgB4iOzqiKuAW4GTRrWZ\nCqwbR1gL7ANcDswHvgPcDRySUnqhxDobIiU45RTYfntYtqxyuw9+MJvT8KG8u1VIktRApd24KaX0\nP+TcpCml1DPiv9cAby2rnmb6z/+Ed72repvtt4fHHoNx4xpTkyRJtfDhUyV65JFij5K++254wxtK\nL0eSpE3mw6dK8PzzMH16flg477xsqMKwIElqdQaGOvvCF2DrreGeeyq3Ofzw7LHTp5/euLokSdoc\nDknUyc9+BrNm5bdbuhR23LH0ciRJqisDw2Z66imYODG/3Q03ZD0LkiS1I4ckNtHQEBx1VH5Y+Pzn\ns3kKhgVJUjuzh2ETXHABfOIT1du87nXZ1Q9bb92YmiRJKpOBoQb33JNd/ZDn4Ydhjz3Kr0eSpEZx\nSKKAVauyGyrlhYXLLsuGHwwLkqROY2CoIiU48cQsLFR7oNdHP5rNaXjf+xpXmyRJjeSQRAU/+hG8\n//3V27zylbBoUXZbZ0mSOpmBYZSHH4apU/Pb3XMP7Ltv+fVIktQKHJIYtmYN7L13flj41reyoQrD\ngiSpmxgYgM99DrbdFubNq9zm6KNh7Vo4afQDuiVJ6gJdPSRx/fXQ25vf7qmnsvkKkiR1q64MDEuX\nws4757e75RY45JDy65EkqdV11ZDEiy/CYYflh4V//MdsnoJhQZKkTNf0MJxzDnzyk9Xb7L8/3H47\nbLVVY2qSJKlddHxgmDsXDjwwv90jj8DkyaWXI0lSW+rYIYmUYPfd88PC5ZdnbQ0LkiRV1rGB4cwz\nYcmSyu+femoWFI45pnE1SZLUrjp2SOKGGza+fJddsvstjBnT2HokSWpnHdvD8Pa3b7js/vvhsccM\nC5Ik1apjexhOOw1e/WqYPx/22w+OOKLZFUmS1L46NjD09MCxxza7CkmSOkPHDklIkqT6MTBIkqRc\nBgZJkpTLwCBJknIZGCRJUi4DgyRJymVgkCRJuQwMkiQpl4FBkiTlMjBIkqRcBgZJkpTLwCBJknIZ\nGCRJUi4DgyRJymVgkCRJuQwMNejv7292CarAc9PaPD+ty3PTulrt3JQWGCLibyPi5xHxh4hYWcN6\nX4yIpRGxOiJ+GhFTyqqxVq128vRHnpvW5vlpXZ6b1tVq56bMHoYtgcuAfy66QkR8FjgV+DjwRuAP\nwHURsVUpFUqSpEK2KGvDKaUvAETECTWsdjrwjymlq4bXPR5YDryTLHxIkqQmaJk5DBHxamAScOO6\nZSmlZ4C5wEHNqkuSJJXYw7AJJgGJrEdhpOXD71WyDcC8efNKKuuPVq1axeDgYOmfo9p5blqb56d1\neW5aVyPOzYjvzm3y2kZKqfCGI+IM4LNVmiRgr5TSghHrnACcm1J6Rc62DwJuB3ZKKS0fsfxHwFBK\nqa/Ceh8A/q3wTkiSpNE+mFL6QbUGtfYwnAVcnNNmcY3bXOdJIICJrN/LMBG4p8p61wEfBB4B1mzi\nZ0uS1I22AXYj+y6tqqbAkFJaAazYtJpyt70kIp4EDgd+BRARLwcOAL6ZU1PVVCRJkir6RZFGZd6H\nYZeIeD0wGeiJiNcPv8aMaPNQRBw7YrXzgP8TEUdHxOuAfwV+DVxeVp2SJClfmZMevwgcP+LndTM3\nZgG3Dv/3VGDsugYppTMjYjvg28A44DbgbSml50usU5Ik5ahp0qMkSepOLXMfBkmS1LoMDJIkKZeB\noUYRMTkiLoyIxcMPyFoYEf8QEVs2uzZlNvXBZ6q/iPhERCyJiGcj4s6I2L/ZNQkiYmZEXBERT0TE\nUEQc0+yalImIv4mIuyLimYhYHhE/iYhpza4LDAyb4jVk94v4GLA3MAc4GfhSM4vSemp+8JnqLyKO\nA84G/h7YD7iP7GFyE5pamADGAPcCp5DdcE+tYybwdbJbCryF7PfZ9RGxbVOrwkmPdRERnwJOTim1\nzKO4VfwuoypHRNwJzE0pnT78cwCPA+enlM5sanF6SUQMAe9MKV3R7Fq0oeGA/RRwSErp9mbWYg9D\nfYwD7PqWhg0P0c1g/YfJJeAGfJicVItxZL1ATf+OMTBspoiYApwKfKvZtUgtZALQQ+0Pk5M0bLhX\n7jzg9pTSg82ux8AwLCLOGJ78U+m1dvTEk4jYGbgG+FFK6bvNqbw7bMr5kaQ2dwHZXLn3N7sQaK3H\nWzdbTQ/WioidgJvIkt9JZRYmoNwHn6n+fgusJXt43EgTyR40J6mKiPgGcBQwM6W0rNn1gIHhJbU8\nWGu4Z+Em4G7gI2XWpUyZDz5T/aWUXoiIAbKHyV0BL3WvHg6c38zapFY3HBaOBQ5NKT3W7HrWMTDU\naLhn4WfAEuAzwKuy34OQUho9XqsmiIhdgFcw4sFnw289nFL6Q/Mq6zrnAJcMB4e7yC5B3g64pJlF\nCYYfAjiF7BJxgN2H/3+yMqX0ePMqU0RcAPQBxwB/iIh1vXSrUkprmleZl1XWbPhSvdHzFYJsEnhP\nE0rSKBFxMes/+GydWSmlWzeyXCWJiFPIgvVEsuv+T0sp/bK5VSkiDgVuZsN7MFyaUrLXtImGL3Pd\n2BfziSmlf210PSMZGCRJUi6vkpAkSbkMDJIkKZeBQZIk5TIwSJKkXAYGSZKUy8AgSZJyGRgkSVIu\nA4MkScplYJAkSbkMDJIkKZeBQZIk5fr/Y7KW83KEexwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x9e9e908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "#Using Linear Model \n",
    "print ('Linear Model Starts Here:')\n",
    "\n",
    "#Intialize\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "\n",
    "# Fit\n",
    "regr.fit(trainX, trainY);\n",
    "\n",
    "# The Coefficients\n",
    "print ('Coefficients:', regr.coef_)\n",
    "\n",
    "#Predict\n",
    "predictY = regr.predict(testX)\n",
    "print(regr.predict(-1))\n",
    "#The mean squared error\n",
    "print(\"Mean squared error: %.2f\" % np.mean((predictY) - testY) **2  ) # (y^ - y)^2\n",
    "\n",
    "#Explained variance score: 1 is perfect\n",
    "print ('Variance score: %.2f' % regr.score(testX, testY))\n",
    "\n",
    "#plot outputs \n",
    "YPositive = [1] * len(XPositive[-20:])\n",
    "YZero = [0] * len(XNegative[-20:])\n",
    "plt.scatter(XPositive[-20:], YPositive, color='black')\n",
    "plt.plot(testX, predictY, color='blue', linewidth=3)\n",
    "plt.scatter(XNegative[-20:], YZero , color='red')\n",
    "\n",
    "\n",
    "plt.axis('equal')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3 - kNN Model\n",
    "a) Write the code to compute a KNN model. Apply it to the dataset created in Exercise 1. Plot the predicted class for a regular grid in R^2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import neighbors\n",
    "\n",
    "for weights in ['uniform', 'distance']:\n",
    "    clf = neighbors.KNeighborsClassifier(2, weights=weights)\n",
    "   # clf.fit(trainX,trainY)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn import neighbors, datasets\n",
    "\n",
    "n_neighbors = 15\n",
    "\n",
    "# import some data to play with\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, :2]  # we only take the first two features. We could\n",
    "                      # avoid this ugly slicing by using a two-dim dataset\n",
    "y = iris.target\n",
    "\n",
    "h = .02  # step size in the mesh\n",
    "\n",
    "# Create color maps\n",
    "cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA', '#AAAAFF'])\n",
    "cmap_bold = ListedColormap(['#FF0000', '#00FF00', '#0000FF'])\n",
    "\n",
    "for weights in ['uniform', 'distance']:\n",
    "    # we create an instance of Neighbours Classifier and fit the data.\n",
    "    clf = neighbors.KNeighborsClassifier(n_neighbors, weights=weights)\n",
    "    clf.fit(X, y)\n",
    "\n",
    "    # Plot the decision boundary. For that, we will assign a color to each\n",
    "    # point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "    # Put the result into a color plot\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.figure()\n",
    "    plt.pcolormesh(xx, yy, Z, cmap=cmap_light)\n",
    "\n",
    "    # Plot also the training points\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=cmap_bold)\n",
    "    plt.xlim(xx.min(), xx.max())\n",
    "    plt.ylim(yy.min(), yy.max())\n",
    "    plt.title(\"3-Class classification (k = %i, weights = '%s')\"\n",
    "              % (n_neighbors, weights))\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
