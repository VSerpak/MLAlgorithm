{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# y = mx + b\n",
    "# m is slope, b is y-intercept\n",
    "\n",
    "#x = input \n",
    "#y = outputs\n",
    "\n",
    "from numpy import * \n",
    "#import numpy as np \n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def LoadData():\n",
    "    points = genfromtxt(\"input/data.csv\", delimiter=\",\")\n",
    "    return points \n",
    "\n",
    "def InitializeHyperparameters():\n",
    "    b = 0\n",
    "    m = 0 \n",
    "    learning_rate = 0.0001\n",
    "    num_iterations = 1000\n",
    "    return [b , m , learning_rate, num_iterations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GetGradientDescent(b_current, m_current, points,learning_rate):\n",
    "    b_gradient = 0\n",
    "    m_gradient = 0\n",
    "    N = float(len(points))\n",
    "    for i in range(0, len(points)):\n",
    "        x = points[i, 0]\n",
    "        y = points[i, 1]\n",
    "        b_gradient += -(2/N) * (y - ((m_current * x) + b_current))\n",
    "        m_gradient += -(2/N) * x * (y - ((m_current * x) + b_current))\n",
    "        \n",
    "    new_b = b_current - (learning_rate * b_gradient)\n",
    "    new_m = m_current - (learning_rate * m_gradient)\n",
    "   \n",
    "    return [new_b, new_m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ComputerError(b,m,points):\n",
    "    totalError = 0\n",
    "    for i in range(len(points)):\n",
    "        x = points[i, 0]\n",
    "        y = points[i, 1]\n",
    "        totalError += (y - (m * x + b)) ** 2\n",
    "    return totalError / float(len(points))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def RunAlgorithm(starting_b, starting_m, learning_rate, num_iterations, points):\n",
    "    b = starting_b\n",
    "    m = starting_m\n",
    "    for i in range(num_iterations):\n",
    "        b, m = GetGradientDescent(b, m, array(points), learning_rate)\n",
    "        error = ComputerError(b, m, points)\n",
    "        if error < float64(2.0):\n",
    "            print(error)\n",
    "            return [b, m]\n",
    "        if i % 100 == 0: \n",
    "            print (\"After {0} iterations b = {1}, m = {2}, error = {3}\".format(i, b, m, ComputerError(b, m, points)))\n",
    "    return [b, m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def Run():\n",
    "    points =  LoadData()\n",
    "    [b, m, learning_rate,num_iterations] = InitializeHyperparameters()\n",
    "    print (\"Starting gradient descent at b = {0}, m = {1}, error = {2}\".format(b, m, ComputerError(b, m, points)))\n",
    "    print (\"Running...\")\n",
    "    [b_new, m_new] = RunAlgorithm( b, m, learning_rate, num_iterations, points)\n",
    "    print (\"After {0} iterations b = {1}, m = {2}, error = {3}\".format(num_iterations, b_new, m_new, ComputerError(b_new, m_new, points)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting gradient descent at b = 0, m = 0, error = 5565.107834483211\n",
      "Running...\n",
      "After 0 iterations b = 0.014547010110737297, m = 0.7370702973591052, error = 1484.586557408649\n",
      "After 100 iterations b = 0.035135020029129285, m = 1.4788015372774521, error = 112.64702056974568\n",
      "After 200 iterations b = 0.04113767542736797, m = 1.478683556914539, error = 112.64341600405817\n",
      "After 300 iterations b = 0.047135801867801, m = 1.4785656655669115, error = 112.63981687555349\n",
      "After 400 iterations b = 0.05312940276749252, m = 1.4784478631674083, error = 112.63622317603011\n",
      "After 500 iterations b = 0.05911848154092854, m = 1.478330149648919, error = 112.63263489729884\n",
      "After 600 iterations b = 0.06510304160001891, m = 1.4782125249443832, error = 112.62905203118288\n",
      "After 700 iterations b = 0.07108308635409925, m = 1.4780949889867918, error = 112.62547456951779\n",
      "After 800 iterations b = 0.0770586192099327, m = 1.4779775417091856, error = 112.62190250415141\n",
      "After 900 iterations b = 0.08302964357171226, m = 1.4778601830446565, error = 112.61833582694376\n",
      "After 1000 iterations b = 0.08893651993741346, m = 1.4777440851894448, error = 112.61481011613473\n"
     ]
    }
   ],
   "source": [
    " Run()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
