{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# y = mx + b\n",
    "# m is slope, b is y-intercept\n",
    "\n",
    "#x = input \n",
    "#y = outputs\n",
    "\n",
    "from numpy import * \n",
    "#import numpy as np \n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def LoadData():\n",
    "    points = genfromtxt(\"input/data.csv\", delimiter=\",\")\n",
    "    return points \n",
    "\n",
    "def InitializeHyperparameters():\n",
    "    b = 0\n",
    "    m = 0 \n",
    "    learning_rate = 0.0001\n",
    "    num_iterations = 1000\n",
    "    return [b , m , learning_rate, num_iterations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GetGradientDescent(b_current, m_current, points,learning_rate):\n",
    "    b_gradient = 0\n",
    "    m_gradient = 0\n",
    "    N = float(len(points))\n",
    "    for i in range(0, len(points)):\n",
    "        x = points[i, 0]\n",
    "        y = points[i, 1]\n",
    "        b_gradient += -(2/N) * (y - ((m_current * x) + b_current))\n",
    "        m_gradient += -(2/N) * x * (y - ((m_current * x) + b_current))\n",
    "        \n",
    "    new_b = b_current - (learning_rate * b_gradient)\n",
    "    new_m = m_current - (learning_rate * m_gradient)\n",
    "   \n",
    "    return [new_b, new_m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ComputerError(b,m,points):\n",
    "    totalError = 0\n",
    "    for i in range(len(points)):\n",
    "        x = points[i, 0]\n",
    "        y = points[i, 1]\n",
    "        totalError += (y - (m * x + b)) ** 2\n",
    "    return totalError / float(len(points))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def RunAlgorithm(starting_b, starting_m, learning_rate, num_iterations, points):\n",
    "    b = starting_b\n",
    "    m = starting_m\n",
    "    for i in range(num_iterations):\n",
    "        b, m = GetGradientDescent(b, m, array(points), learning_rate)\n",
    "        error = ComputerError(b, m, points)\n",
    "        if error < float64(2.0):\n",
    "            print(error)\n",
    "            return [b, m]\n",
    "        if i % 100 == 0: \n",
    "            print (\"After {0} iterations b = {1}, m = {2}, error = {3}\".format(i, b, m, ComputerError(b, m, points)))\n",
    "    return [b, m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def Run():\n",
    "    points =  LoadData()\n",
    "    [b, m, learning_rate,num_iterations] = InitializeHyperparameters()\n",
    "    print (\"Starting gradient descent at b = {0}, m = {1}, error = {2}\".format(b, m, ComputerError(b, m, points)))\n",
    "    print (\"Running...\")\n",
    "    [b_new, m_new] = RunAlgorithm( b, m, learning_rate, num_iterations, points)\n",
    "    print (\"After {0} iterations b = {1}, m = {2}, error = {3}\".format(num_iterations, b_new, m_new, ComputerError(b_new, m_new, points)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting gradient descent at b = 0, m = 0, error = 5565.107834483211\n",
      "Running...\n",
      "After 0 iterations b = 0.014547010110737297, m = 0.7370702973591052, error = 1484.586557408649\n",
      "After 100 iterations b = 0.035135020029129285, m = 1.4788015372774521, error = 112.64702056974568\n",
      "After 200 iterations b = 0.04113767542736797, m = 1.478683556914539, error = 112.64341600405817\n",
      "After 300 iterations b = 0.047135801867801, m = 1.4785656655669115, error = 112.63981687555349\n",
      "After 400 iterations b = 0.05312940276749252, m = 1.4784478631674083, error = 112.63622317603011\n",
      "After 500 iterations b = 0.05911848154092854, m = 1.478330149648919, error = 112.63263489729884\n",
      "After 600 iterations b = 0.06510304160001891, m = 1.4782125249443832, error = 112.62905203118288\n",
      "After 700 iterations b = 0.07108308635409925, m = 1.4780949889867918, error = 112.62547456951779\n",
      "After 800 iterations b = 0.0770586192099327, m = 1.4779775417091856, error = 112.62190250415141\n",
      "After 900 iterations b = 0.08302964357171226, m = 1.4778601830446565, error = 112.61833582694376\n",
      "After 1000 iterations b = 0.08899616284106236, m = 1.4777429129263462, error = 112.61477452976749\n",
      "After 1100 iterations b = 0.09495818041704095, m = 1.4776257312874477, error = 112.61121860450699\n",
      "After 1200 iterations b = 0.10091569969614136, m = 1.4775086380612037, error = 112.60766804305943\n",
      "After 1300 iterations b = 0.1068687240722944, m = 1.4773916331809076, error = 112.60412283733388\n",
      "After 1400 iterations b = 0.11281725693687011, m = 1.477274716579903, error = 112.60058297925153\n",
      "After 1500 iterations b = 0.11876130167867975, m = 1.477157888191584, error = 112.59704846074615\n",
      "After 1600 iterations b = 0.12470086168397787, m = 1.4770411479493946, error = 112.59351927376329\n",
      "After 1700 iterations b = 0.1306359403364639, m = 1.476924495786829, error = 112.58999541026087\n",
      "After 1800 iterations b = 0.13656654101728474, m = 1.4768079316374325, error = 112.58647686220885\n",
      "After 1900 iterations b = 0.14249266710503547, m = 1.4766914554347994, error = 112.58296362158924\n",
      "After 2000 iterations b = 0.1484143219757627, m = 1.4765750671125744, error = 112.57945568039635\n",
      "After 2100 iterations b = 0.15433150900296577, m = 1.4764587666044526, error = 112.57595303063636\n",
      "After 2200 iterations b = 0.16024423155759865, m = 1.4763425538441792, error = 112.57245566432762\n",
      "After 2300 iterations b = 0.16615249300807156, m = 1.4762264287655484, error = 112.5689635735005\n",
      "After 2400 iterations b = 0.17205629672025377, m = 1.4761103913024058, error = 112.56547675019732\n",
      "After 2500 iterations b = 0.17795564605747488, m = 1.4759944413886457, error = 112.56199518647264\n",
      "After 2600 iterations b = 0.18385054438052695, m = 1.475878578958213, error = 112.55851887439263\n",
      "After 2700 iterations b = 0.18974099504766648, m = 1.475762803945102, error = 112.55504780603573\n",
      "After 2800 iterations b = 0.1956270014146158, m = 1.4756471162833573, error = 112.55158197349218\n",
      "After 2900 iterations b = 0.2015085668345655, m = 1.4755315159070725, error = 112.54812136886423\n",
      "After 3000 iterations b = 0.2073856946581765, m = 1.475416002750392, error = 112.54466598426593\n",
      "After 3100 iterations b = 0.21325838823358123, m = 1.4753005767475085, error = 112.54121581182343\n",
      "After 3200 iterations b = 0.2191266509063863, m = 1.4751852378326658, error = 112.53777084367465\n",
      "After 3300 iterations b = 0.22499048601967409, m = 1.4750699859401564, error = 112.5343310719692\n",
      "After 3400 iterations b = 0.2308498969140044, m = 1.4749548210043226, error = 112.53089648886879\n",
      "After 3500 iterations b = 0.23670488692741676, m = 1.474839742959556, error = 112.52746708654682\n",
      "After 3600 iterations b = 0.24255545939543233, m = 1.4747247517402986, error = 112.52404285718852\n",
      "After 3700 iterations b = 0.2484016176510553, m = 1.4746098472810407, error = 112.52062379299088\n",
      "After 3800 iterations b = 0.2542433650247753, m = 1.4744950295163224, error = 112.51720988616283\n",
      "After 3900 iterations b = 0.26008070484456947, m = 1.474380298380734, error = 112.5138011289247\n",
      "After 4000 iterations b = 0.2659136404359036, m = 1.4742656538089138, error = 112.51039751350899\n",
      "After 4100 iterations b = 0.27174217512173415, m = 1.4741510957355504, error = 112.50699903215941\n",
      "After 4200 iterations b = 0.2775663122225113, m = 1.4740366240953813, error = 112.50360567713201\n",
      "After 4300 iterations b = 0.2833860550561791, m = 1.4739222388231934, error = 112.5002174406939\n",
      "After 4400 iterations b = 0.28920140693817875, m = 1.4738079398538226, error = 112.49683431512435\n",
      "After 4500 iterations b = 0.29501237118145024, m = 1.4736937271221544, error = 112.49345629271379\n",
      "After 4600 iterations b = 0.30081895109643303, m = 1.4735796005631225, error = 112.49008336576466\n",
      "After 4700 iterations b = 0.30662114999106993, m = 1.4734655601117108, error = 112.48671552659093\n",
      "After 4800 iterations b = 0.31241897117080736, m = 1.4733516057029516, error = 112.48335276751794\n",
      "After 4900 iterations b = 0.31821241793859745, m = 1.4732377372719263, error = 112.47999508088296\n",
      "After 5000 iterations b = 0.32400149359490094, m = 1.4731239547537658, error = 112.47664245903474\n",
      "After 5100 iterations b = 0.3297862014376882, m = 1.4730102580836488, error = 112.47329489433318\n",
      "After 5200 iterations b = 0.3355665447624418, m = 1.4728966471968041, error = 112.46995237915021\n",
      "After 5300 iterations b = 0.34134252686215644, m = 1.4727831220285086, error = 112.46661490586905\n",
      "After 5400 iterations b = 0.3471141510273438, m = 1.4726696825140886, error = 112.46328246688435\n",
      "After 5500 iterations b = 0.35288142054603217, m = 1.4725563285889187, error = 112.4599550546023\n",
      "After 5600 iterations b = 0.3586443387037693, m = 1.4724430601884222, error = 112.45663266144064\n",
      "After 5700 iterations b = 0.3644029087836235, m = 1.472329877248072, error = 112.45331527982835\n",
      "After 5800 iterations b = 0.3701571340661872, m = 1.4722167797033885, error = 112.45000290220592\n",
      "After 5900 iterations b = 0.3759070178295766, m = 1.4721037674899418, error = 112.4466955210253\n",
      "After 6000 iterations b = 0.38165256334943415, m = 1.4719908405433497, error = 112.44339312874973\n",
      "After 6100 iterations b = 0.38739377389893226, m = 1.4718779987992794, error = 112.44009571785398\n",
      "After 6200 iterations b = 0.39313065274877274, m = 1.4717652421934457, error = 112.43680328082404\n",
      "After 6300 iterations b = 0.39886320316719037, m = 1.471652570661613, error = 112.43351581015709\n",
      "After 6400 iterations b = 0.4045914284199533, m = 1.4715399841395935, error = 112.43023329836201\n",
      "After 6500 iterations b = 0.41031533177036655, m = 1.4714274825632478, error = 112.4269557379586\n",
      "After 6600 iterations b = 0.41603491647927215, m = 1.471315065868485, error = 112.42368312147812\n",
      "After 6700 iterations b = 0.42175018580505264, m = 1.4712027339912628, error = 112.42041544146318\n",
      "After 6800 iterations b = 0.42746114300363147, m = 1.471090486867587, error = 112.41715269046745\n",
      "After 6900 iterations b = 0.4331677913284758, m = 1.4709783244335113, error = 112.41389486105598\n",
      "After 7000 iterations b = 0.43887013403059805, m = 1.4708662466251385, error = 112.410641945805\n",
      "After 7100 iterations b = 0.44456817435855794, m = 1.470754253378619, error = 112.40739393730182\n",
      "After 7200 iterations b = 0.45026191555846373, m = 1.4706423446301515, error = 112.40415082814506\n",
      "After 7300 iterations b = 0.45595136087397475, m = 1.4705305203159829, error = 112.40091261094437\n",
      "After 7400 iterations b = 0.4616365135463037, m = 1.470418780372408, error = 112.39767927832091\n",
      "After 7500 iterations b = 0.46731737681421687, m = 1.47030712473577, error = 112.39445082290645\n",
      "After 7600 iterations b = 0.4729939539140369, m = 1.4701955533424598, error = 112.39122723734427\n",
      "After 7700 iterations b = 0.4786662480796454, m = 1.4700840661289167, error = 112.38800851428857\n",
      "After 7800 iterations b = 0.48433426254248346, m = 1.4699726630316277, error = 112.38479464640464\n",
      "After 7900 iterations b = 0.4899980005315543, m = 1.4698613439871275, error = 112.38158562636902\n",
      "After 8000 iterations b = 0.49565746527342514, m = 1.4697501089319989, error = 112.3783814468689\n",
      "After 8100 iterations b = 0.5013126599922277, m = 1.469638957802873, error = 112.37518210060287\n",
      "After 8200 iterations b = 0.5069635879096627, m = 1.4695278905364275, error = 112.37198758028042\n",
      "After 8300 iterations b = 0.5126102522449987, m = 1.4694169070693894, error = 112.36879787862199\n",
      "After 8400 iterations b = 0.5182526562150757, m = 1.4693060073385322, error = 112.36561298835903\n",
      "After 8500 iterations b = 0.5238908030343076, m = 1.469195191280678, error = 112.36243290223393\n",
      "After 8600 iterations b = 0.5295246959146824, m = 1.4690844588326957, error = 112.35925761300017\n",
      "After 8700 iterations b = 0.535154338065764, m = 1.4689738099315024, error = 112.35608711342185\n",
      "After 8800 iterations b = 0.5407797326946953, m = 1.468863244514063, error = 112.35292139627441\n",
      "After 8900 iterations b = 0.5464008830061995, m = 1.4687527625173895, error = 112.34976045434378\n",
      "After 9000 iterations b = 0.5520177922025822, m = 1.4686423638785413, error = 112.34660428042694\n",
      "After 9100 iterations b = 0.557630463483732, m = 1.4685320485346258, error = 112.34345286733192\n",
      "After 9200 iterations b = 0.5632389000471242, m = 1.4684218164227978, error = 112.3403062078773\n",
      "After 9300 iterations b = 0.5688431050878204, m = 1.468311667480259, error = 112.33716429489263\n",
      "After 9400 iterations b = 0.574443081798473, m = 1.4682016016442587, error = 112.33402712121817\n",
      "After 9500 iterations b = 0.580038833369324, m = 1.4680916188520938, error = 112.33089467970531\n",
      "After 9600 iterations b = 0.5856303629882099, m = 1.4679817190411086, error = 112.32776696321567\n",
      "After 9700 iterations b = 0.5912176738405615, m = 1.4678719021486941, error = 112.32464396462223\n",
      "After 9800 iterations b = 0.5968007691094057, m = 1.4677621681122892, error = 112.3215256768083\n",
      "After 9900 iterations b = 0.6023796519753677, m = 1.467652516869379, error = 112.31841209266808\n",
      "After 10000 iterations b = 0.6078985997054931, m = 1.4675440436333027, error = 112.31533427075733\n"
     ]
    }
   ],
   "source": [
    " Run()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
